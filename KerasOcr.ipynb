{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MadalinaStefan/OCR_comparison/blob/main/KerasOcr.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ns_uRnhr3E46"
      },
      "source": [
        "# **I sistemi di riconoscimento ottico dei caratteri: confronto tra Keras Ocr, Tesseract e Easy Ocr**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "La fase preliminare prevede l'installazione e l'importazione delle librerie necessarie."
      ],
      "metadata": {
        "id": "olB1-xQlVXg9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b70XPGSfSgZ0"
      },
      "outputs": [],
      "source": [
        "!pip install keras_ocr\n",
        "!pip install pybind11\n",
        "!pip3 install fastwer"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Il dataset di immagini (cartella \"dataset_immagini\") e i file .csv conteneti il golden text (cartella \"golden_text\") sono situati e vengono importati da google Drive."
      ],
      "metadata": {
        "id": "_DI-eMrKVefl"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LcUPRg6mOTTX"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "import keras_ocr\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import fastwer\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "pipeline = keras_ocr.pipeline.Pipeline()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Acquisizione delle immagini"
      ],
      "metadata": {
        "id": "2QCBIUPhV1vd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Il codice seguente è stato utilizzato per associare a ciasciuna immagine (contenuta nel dataset immagini), il corrispettivo testo golden. Vengono create inizialmente tre liste vuote che verranno popolate con le immagini, le cartelle e il testo golden.\n",
        "Ad ogni elemento presente nel dataset delle immagini, divise per tipologia, viene associato il corrispondente file .csv che contiene i testi golden di quella determinata categoria di immagini. L'associazione viene effetuata attraverso la corrispondenza dei nomi delle cartelle del dataset e dei nomi dei file .csv.\n"
      ],
      "metadata": {
        "id": "3heyFTEXVnEv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jpIo7r-tO9g0"
      },
      "outputs": [],
      "source": [
        "images_folder = '/content/drive/MyDrive/dataset_immagini'\n",
        "csv_folder = '/content/drive/MyDrive/golden_text'\n",
        "\n",
        "images = []\n",
        "labels = []\n",
        "true_texts = []\n",
        "\n",
        "for folder_class in os.listdir(images_folder):\n",
        "  path = csv_folder + '/' + folder_class + '.csv'\n",
        "  texts = pd.read_csv(path).values\n",
        "\n",
        "\n",
        "  for file in os.listdir(images_folder + '/' + folder_class):\n",
        "    if file.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
        "      images.append(images_folder + '/' + folder_class + '/' + file)\n",
        "      labels.append(folder_class)\n",
        "      index = int(file.split('.')[0])\n",
        "      true_texts.append(texts[index][0])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WekUCwlgKhz7"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Le immagini vengono lette attraverso keras_ocr e successivamente convertite in array."
      ],
      "metadata": {
        "id": "cWbJTyeSV8id"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V4xXuqjjPqCS"
      },
      "outputs": [],
      "source": [
        "images_path = images\n",
        "images = [keras_ocr.tools.read(img) for img in images]\n",
        "images = np.array(images)\n",
        "images_path = np.array(images_path)\n",
        "true_texts = np.array(true_texts)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Visualizzazione delle immagini"
      ],
      "metadata": {
        "id": "YGAolH9sWFdg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "La funzione visualize_images permette di visualizzare le immagini in una griglia di 4 righe e 5 colonne. Prende in input l'elenco delle immagini; con il parametro gray permette di visualizzare le immagini in negativo."
      ],
      "metadata": {
        "id": "fTxx0aKoWLDP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fa3_On_iTDJI"
      },
      "outputs": [],
      "source": [
        "def visualize_images(images, grey=False):\n",
        "  f, grid_plot = plt.subplots(4, 5, figsize=(20,40))\n",
        "\n",
        "  if grey:\n",
        "    grid_plot[0,0].imshow(images[0], cmap='Greys')\n",
        "    grid_plot[0,1].imshow(images[1], cmap='Greys')\n",
        "    grid_plot[0,2].imshow(images[2], cmap='Greys')\n",
        "    grid_plot[0,3].imshow(images[3], cmap='Greys')\n",
        "    grid_plot[0,4].imshow(images[4], cmap='Greys')\n",
        "    grid_plot[1,0].imshow(images[5], cmap='Greys')\n",
        "    grid_plot[1,1].imshow(images[6], cmap='Greys')\n",
        "    grid_plot[1,2].imshow(images[7], cmap='Greys')\n",
        "    grid_plot[1,3].imshow(images[8], cmap='Greys')\n",
        "    grid_plot[1,4].imshow(images[9], cmap='Greys')\n",
        "    grid_plot[2,0].imshow(images[10], cmap='Greys')\n",
        "    grid_plot[2,1].imshow(images[11], cmap='Greys')\n",
        "    grid_plot[2,2].imshow(images[12], cmap='Greys')\n",
        "    grid_plot[2,3].imshow(images[13], cmap='Greys')\n",
        "    grid_plot[2,4].imshow(images[14], cmap='Greys')\n",
        "    grid_plot[3,0].imshow(images[15], cmap='Greys')\n",
        "    grid_plot[3,1].imshow(images[16], cmap='Greys')\n",
        "    grid_plot[3,2].imshow(images[17], cmap='Greys')\n",
        "    grid_plot[3,3].imshow(images[18], cmap='Greys')\n",
        "    grid_plot[3,4].imshow(images[19], cmap='Greys')\n",
        "  else:\n",
        "    grid_plot[0,0].imshow(images[0])\n",
        "    grid_plot[0,1].imshow(images[1])\n",
        "    grid_plot[0,2].imshow(images[2])\n",
        "    grid_plot[0,3].imshow(images[3])\n",
        "    grid_plot[0,4].imshow(images[4])\n",
        "    grid_plot[1,0].imshow(images[5])\n",
        "    grid_plot[1,1].imshow(images[6])\n",
        "    grid_plot[1,2].imshow(images[7])\n",
        "    grid_plot[1,3].imshow(images[8])\n",
        "    grid_plot[1,4].imshow(images[9])\n",
        "    grid_plot[2,0].imshow(images[10])\n",
        "    grid_plot[2,1].imshow(images[11])\n",
        "    grid_plot[2,2].imshow(images[12])\n",
        "    grid_plot[2,3].imshow(images[13])\n",
        "    grid_plot[2,4].imshow(images[14])\n",
        "    grid_plot[3,0].imshow(images[15])\n",
        "    grid_plot[3,1].imshow(images[16])\n",
        "    grid_plot[3,2].imshow(images[17])\n",
        "    grid_plot[3,3].imshow(images[18])\n",
        "    grid_plot[3,4].imshow(images[19])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Ridimensionamento immagini"
      ],
      "metadata": {
        "id": "76mdxPaCWQOr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Le immagini vengono ridimensionate attraverso la funzione resize_image, la quale prende le immagini e con il parametro scale_percent impostato a 25, le ridimensiona del 25% rispetto alle dimensioni originali. Le dimensioni di larghezza e altezza vengono calcolate sulla base della percentuale di ridimensionamento."
      ],
      "metadata": {
        "id": "Gbn54iNLWUzC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iQrDKT98S87E"
      },
      "outputs": [],
      "source": [
        "def resize_image(img, scale_percent=25):\n",
        "  width = int(img.shape[1] * scale_percent / 100)\n",
        "  height = int(img.shape[0] * scale_percent / 100)\n",
        "  dim = (width, height)\n",
        "\n",
        "  return cv2.resize(img, dim, interpolation = cv2.INTER_CUBIC)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Pre-elaborazione"
      ],
      "metadata": {
        "id": "9-oeCHruWZfd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nella fase di pre-elaborazione le immagini subiscono tre trasformazioni: offuscamento, rotazione di 90º e conversione in negativo. Le trasformazioni si applicano sia sulle immegini high quality (le immagini originali del dataset) e sia sulle immagini ridimensionate, che verranno definite come immagini low quality. Infine vengono visualizzate le immagini, con il paramentro false vengono visualizzate le immagini originali, con il parametro true applicato alle immagini trasformate verranno visualizzate le immagini con la trasformazione selezionata."
      ],
      "metadata": {
        "id": "32K50nKzWeBC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eQyaHll2e-MN"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def image_transform(images, t_type, scale = False):\n",
        "  transform_images = []\n",
        "  images_scaled = []\n",
        "\n",
        "  if scale:\n",
        "    for img in images:\n",
        "      images_scaled.append(resize_image(img, 25))\n",
        "  else:\n",
        "    images_scaled = images\n",
        "\n",
        "  for img in images:\n",
        "    if t_type == 'blur':\n",
        "      image = cv2.blur(img, (7, 7))\n",
        "    elif t_type == 'rotation':\n",
        "      image = cv2.rotate(img, cv2.ROTATE_90_CLOCKWISE)\n",
        "    else:\n",
        "      image =  cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "\n",
        "    transform_images.append(image)\n",
        "\n",
        "  return transform_images\n",
        "\n",
        "t_images = image_transform(images, 'gray') #rotation, blur o gray\n",
        "\n",
        "visualize_images(images, False) #visualizza le immagini natural\n",
        "#visualize_images(t_images, True) #visualizza le trasformazioni"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SLdbpw-jBoAj"
      },
      "source": [
        "# **KERAS-OCR**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fSfLxUHAH1Ga"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from PIL import Image\n",
        "#assert tf.test.is_gpu_available(), 'No GPU is available.'"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Prova sulle immagini in negativo"
      ],
      "metadata": {
        "id": "7i_4TQcie2Ll"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rgb_image = cv2.cvtColor(t_images[0], cv2.COLOR_GRAY2RGB)\n",
        "\n",
        "img = Image.fromarray(t_images[0], 'L')\n",
        "img"
      ],
      "metadata": {
        "id": "Gk1CcvYtr76n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f71hQ5zHG0w6"
      },
      "outputs": [],
      "source": [
        "#predictions = pipeline.recognize([images[0]])\n",
        "#predictions = pipeline.recognize([t_images[0]])\n",
        "#predictions"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Il riconoscimento ottico dei caratteri"
      ],
      "metadata": {
        "id": "0r-y5wd1XaRo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Per il riconoscimento del testo contenuto in ciascuna immagine si utilizza una pipeline per ottenere le previsioni dei caratteri riconosciuti. I testi predetti vengono aggiunti ad una stringa temporanea e successivamente aggiunti alla lista pred_texts."
      ],
      "metadata": {
        "id": "NN7_gDA7c8OJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GvkhEwv3Ox7I"
      },
      "outputs": [],
      "source": [
        "pred_texts = []\n",
        "\n",
        "for image in images:\n",
        "  predictions = pipeline.recognize([image])\n",
        "\n",
        "  for prediction in predictions:\n",
        "    tmp = ''\n",
        "\n",
        "    for text, box in prediction:\n",
        "        print(f'Testo: {text}')\n",
        "        if tmp == '':\n",
        "          tmp = tmp + text\n",
        "        else:\n",
        "          tmp = tmp + ' ' + text\n",
        "\n",
        "    pred_texts.append(tmp)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BzJ3-XElO7R0"
      },
      "outputs": [],
      "source": [
        "from PIL import Image"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "La funzione ocr_on_folder esegue il riconoscimento ottico dei caratteri su una serie di immagini all'interno di una cartella. Il testo di ogni gruppo di previsioni viene reccolto in una stringa e successivamente tutte le stringhe di ogni immagine vengono raggruppate nella lista pred_texts."
      ],
      "metadata": {
        "id": "Eypl85s6dzOJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "usZCDpa5ML9g"
      },
      "outputs": [],
      "source": [
        "from re import L\n",
        "\n",
        "def ocr_on_folder(images):\n",
        "    pipeline = keras_ocr.pipeline.Pipeline()\n",
        "\n",
        "    pred_texts = []\n",
        "\n",
        "    for image_path in images:\n",
        "        image = keras_ocr.tools.read(image_path)\n",
        "        prediction_groups = pipeline.recognize([image])\n",
        "        text = ' '.join([word_info[0] for word_info in prediction_groups[0]])\n",
        "        pred_texts.append(text)\n",
        "\n",
        "    return pred_texts\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GaO4dF7j99Kq"
      },
      "source": [
        "### Metriche di valutazione\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "La seguente funzione calcola i punteggi CER e WER dei risultati prodotti dal programma, prendendo in cosiderazione e confrontanto la lista dei testi predetti con la lista dei testi golden."
      ],
      "metadata": {
        "id": "9kiEfxZCXn9c"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xqBULMyPJuHF"
      },
      "outputs": [],
      "source": [
        "def calculate_scores(pred_texts, true_texts):\n",
        "  scores_cer = [ fastwer.score_sent(pred_texts[i].lower(), true_texts[i].lower(), char_level=True) for i in range(len(pred_texts)) ]\n",
        "\n",
        "  scores_wer = [ fastwer.score_sent(pred_texts[i].lower(), true_texts[i].lower()) for i in range(len(pred_texts)) ]\n",
        "\n",
        "  return scores_cer, scores_wer"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "I risultati CER e WER vengono visualizzati in file .csv per categoria di immagine. Mostrano la trasformazione eseguita e i risultati ottenuti.  "
      ],
      "metadata": {
        "id": "TOvF-7SWXw8S"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EU7n2uGBJwiC"
      },
      "outputs": [],
      "source": [
        "def generate_csv(data_class, trans, cer, wer):\n",
        "  d = {'augmentation': trans, 'cer': cer, 'wer': wer}\n",
        "  df = pd.DataFrame(data=d)\n",
        "\n",
        "  csv_name = data_class + '.csv'\n",
        "  df.to_csv(csv_name, sep=',', index=False)\n",
        "  df"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Viene definita una seconda funziona per l'implementazione dei file .csv contenenti il percorso dell'immagine, il testo golden e il testo predetto."
      ],
      "metadata": {
        "id": "zgcfV_W3X2gM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_text_csv(csv_label, files_path, true_text, pred_texts):\n",
        "  d = {'filename': files_path, 'true_text': true_text, 'pred_text': pred_texts}\n",
        "  df = pd.DataFrame(data=d)\n",
        "  csv_name = csv_label + '.csv'\n",
        "  df.to_csv(csv_name, sep=',', index=False)\n",
        "  return df"
      ],
      "metadata": {
        "id": "0u8ruvMbk2Xt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Risultati"
      ],
      "metadata": {
        "id": "Nt76y6Hrk12c"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ogni immagine all'interno di una categoria di immagini viene analizzata per ciascuna combinazione di qualità (high e low) e per ciascuna trasformazione (natural, blur, rotation, gray).  Se l'immagine è natural (originale, senza trasformazioni) e la qualità è low, allora l'immagine viene ridimensionata; se l'immagine è natural e high, viene presa l'immagine originale. Per quanto riguarda le trasformazioni, se il parametro è diverso da natural e la qualità è high, viene presa l'immagine originale con la trasformazione, altrimenti viene impostato il parametro scale per ottenere le immagini low quality."
      ],
      "metadata": {
        "id": "t3GqH503X_c9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9XyrX5zFJ3gy"
      },
      "outputs": [],
      "source": [
        "labels = np.array(labels)\n",
        "quality = ['high', 'low']\n",
        "augmentation = ['natural', 'blur', 'rotation'] #gray!\n",
        "\n",
        "for label in set(labels):\n",
        "  print(label)\n",
        "  class_index = np.where(labels==label)[0]\n",
        "  test_images = []\n",
        "\n",
        "  column_cer = []\n",
        "  column_wer = []\n",
        "  column_trans = []\n",
        "\n",
        "  for q in quality:\n",
        "    for a in augmentation:\n",
        "      print(q+'-'+a)\n",
        "      if a == 'natural' and q == 'low':\n",
        "        test_images = [resize_image(x) for x in images[class_index]]\n",
        "      elif a == 'natural' and q == 'high':\n",
        "        test_images = images[class_index]\n",
        "\n",
        "      if a != 'natural':\n",
        "        if q == 'high':\n",
        "          test_images = image_transform(images[class_index], a)\n",
        "        else:\n",
        "          test_images = image_transform(images[class_index], a, scale=True)\n",
        "\n",
        "      pred_texts = ocr_on_folder(test_images)\n",
        "\n",
        "      cer, wer = calculate_scores(pred_texts, true_texts[class_index])\n",
        "\n",
        "      column_cer.append(round(np.mean(cer), 2))\n",
        "      column_wer.append(round(np.mean(wer), 2))\n",
        "      column_trans.append(str(q)+'-'+str(a))\n",
        "\n",
        "      # genera un file .csv per ogni label e per ogni trasformazione\n",
        "      # permette di visualizzare il testo predetto e il testo golden\n",
        "      generate_text_csv(label+'-'+str(q)+'-'+str(a), images_path[class_index], true_texts[class_index], pred_texts) #NEW\n",
        "\n",
        "  generate_csv(label, column_trans, column_cer, column_wer)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1tS1llE1GQZX2NHR60cDjHTHez5puJen6",
      "authorship_tag": "ABX9TyNEjva+BfsKjZNAR8bQTBrp",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}